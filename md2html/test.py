#!/usr/bin/env python3
"""
Test runner for md2html
Run with: python -m md2html.test
Generated by claude opus 4.1
"""

import argparse
import sys
from pathlib import Path

# Import test suites
from .testsuite import TestContext
from .testfilepaths import run_filepath_tests
from .testpreprocessing import run_preprocessing_tests

# Registry of available test suites
TEST_SUITES = {
    'filepaths': run_filepath_tests,
    'preprocessing': run_preprocessing_tests,
    # Future: 'server': run_server_tests,
    # Future: 'watch': run_watch_tests,
}

def main():
    parser = argparse.ArgumentParser(
        description="Test runner for md2html",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Available test suites:
  filepaths      File path and DAG generation tests (default)
  preprocessing  Markdown preprocessing and dependency parsing tests

Examples:
  python -m md2html.test                    # Run all test suites
  python -m md2html.test --testsuite=filepaths  # Run specific suite
  python -m md2html.test --quiet            # Show only failures
  python -m md2html.test --veryquiet        # Show only final count
        """
    )

    parser.add_argument(
        '--testsuite',
        choices=list(TEST_SUITES.keys()) + ['all'],
        default='all',
        help='Which test suite to run (default: all)'
    )
    parser.add_argument(
        '-q', '--quiet',
        action='store_true',
        help='Show only failing tests'
    )
    parser.add_argument(
        '-qq', '--veryquiet',
        action='store_true',
        help='Show only final pass/fail count'
    )
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Show extra detail for each test'
    )
    parser.add_argument(
        '--keep-files',
        action='store_true',
        help='Keep test files after completion'
    )

    args = parser.parse_args()

    # Create test context
    ctx = TestContext(
        quiet=args.quiet or args.veryquiet,
        veryquiet=args.veryquiet,
        verbose=args.verbose and not args.quiet and not args.veryquiet,
        keep_files=args.keep_files
    )

    # Determine which suites to run
    if args.testsuite == 'all':
        suites_to_run = list(TEST_SUITES.keys())
    else:
        suites_to_run = [args.testsuite]

    # Run test suites
    total_passed = 0
    total_failed = 0

    for suite_name in suites_to_run:
        run_suite = TEST_SUITES[suite_name]

        if not ctx.veryquiet and len(suites_to_run) > 1:
            ctx.print_header(f"Running {suite_name} tests")

        passed, failed = run_suite(ctx)
        total_passed += passed
        total_failed += failed

        # Show summary for each suite (print_summary handles quiet/veryquiet)
        if len(suites_to_run) > 1:
            ctx.print_summary(passed, failed, suite_name)
            if not ctx.quiet and not ctx.veryquiet:
                print()  # Blank line between suites in normal mode

    # Final summary
    if len(suites_to_run) > 1:
        if ctx.veryquiet:
            print(f"{total_passed}/{total_passed + total_failed} tests passed")
        else:
            ctx.print_header("Overall Results")
            ctx.print_summary(total_passed, total_failed, "all suites")
    else:
        # Single suite
        if ctx.veryquiet:
            print(f"{total_passed}/{total_passed + total_failed} tests passed ({suites_to_run[0]})")
        else:
            # For single suite, show summary with suite name
            ctx.print_summary(total_passed, total_failed, suites_to_run[0])

    return 0 if total_failed == 0 else 1

if __name__ == "__main__":
    sys.exit(main())
